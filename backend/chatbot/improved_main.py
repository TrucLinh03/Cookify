import os
from fastapi import FastAPI, HTTPException, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from typing import List, Optional
import logging
from dotenv import load_dotenv

# Load environment variables t·ª´ .env file
load_dotenv()

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    logger.warning('GOOGLE_API_KEY not set in environment; Gemini calls may fail')
else:
    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY
    genai.configure(api_key=GOOGLE_API_KEY)

# Models
gemini_model = genai.GenerativeModel('models/gemini-2.0-flash-exp')
sentence_model = None  # S·∫Ω ƒë∆∞·ª£c load sau

# Load d·ªØ li·ªáu embeddings
parquet_path = './cooking_qa_embeddings.parquet'
recipes_parquet = './cooking_recipes_embeddings.parquet'
df = None

# Mongo config for optional admin indexing (optional)
try:
    from pymongo import MongoClient
    from bson import ObjectId
    MONGO_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017')
    MONGO_DB = os.getenv('MONGODB_DB', 'cookify')
    MONGO_COLL = os.getenv('MONGODB_COLLECTION', 'recipes')
    mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=2000)
    recipes_coll = mongo_client[MONGO_DB][MONGO_COLL]
    logger.info("MongoDB connected (optional feature)")
except Exception as mongo_error:
    logger.warning(f"MongoDB kh√¥ng kh·∫£ d·ª•ng (optional): {mongo_error}")
    mongo_client = None
    recipes_coll = None
    MongoClient = None
    ObjectId = None

def load_data():
    global df, sentence_model
    try:
        # Load FAQ embeddings
        if os.path.exists(parquet_path):
            df_faq = pd.read_parquet(parquet_path)
            df_faq['source_type'] = 'faq'
            logger.info(f"ƒê√£ load {len(df_faq)} c√¢u h·ªèi t·ª´ {parquet_path}")
        else:
            logger.warning(f"Kh√¥ng t√¨m th·∫•y file {parquet_path}. Vui l√≤ng ch·∫°y create_embeddings_st.py tr∆∞·ªõc.")
            df_faq = pd.DataFrame()

        # Load recipe embeddings if exist
        if os.path.exists(recipes_parquet):
            df_recipes = pd.read_parquet(recipes_parquet)
            df_recipes['source_type'] = 'recipes'
            logger.info(f"ƒê√£ load {len(df_recipes)} recipe embeddings t·ª´ {recipes_parquet}")
        else:
            df_recipes = pd.DataFrame()

        # Normalize/concat
        if not df_faq.empty and not df_recipes.empty:
            # Ensure both have common columns
            df = pd.concat([df_faq, df_recipes], ignore_index=True)
        elif not df_faq.empty:
            df = df_faq.copy()
        elif not df_recipes.empty:
            df = df_recipes.copy()
        else:
            df = pd.DataFrame()

        # Load SentenceTransformer model
        logger.info("ƒêang load SentenceTransformer model...")
        sentence_model = SentenceTransformer(os.getenv('SENTENCE_MODEL_NAME', 'paraphrase-multilingual-MiniLM-L12-v2'))
        logger.info("ƒê√£ load SentenceTransformer model")

    except Exception as e:
        logger.error(f"L·ªói khi load d·ªØ li·ªáu: {e}")
        df = pd.DataFrame()
        sentence_model = None


# Admin router for indexing
admin_router = APIRouter(prefix='/admin')


def build_text_for_embedding(recipe):
    title = recipe.get('title') or recipe.get('name') or ''
    ingredients = recipe.get('ingredients', [])
    if isinstance(ingredients, list):
        ingredients_text = ', '.join([str(i) for i in ingredients])
    else:
        ingredients_text = str(ingredients)
    instructions = recipe.get('instructions', '') or recipe.get('steps', '') or recipe.get('content', '')
    instructions_snip = instructions[:2000]
    text = f"Title: {title}\nIngredients: {ingredients_text}\nInstructions: {instructions_snip}"
    return text


@admin_router.post('/index_recipe')
async def index_recipe(payload: dict):
    """Index a single recipe from MongoDB into the recipe parquet and update in-memory df.
    payload expects: { 'recipe_id': '<id string>' }
    """
    if recipes_coll is None:
        raise HTTPException(status_code=503, detail='MongoDB not available')
    
    recipe_id = payload.get('recipe_id')
    if not recipe_id:
        raise HTTPException(status_code=400, detail='recipe_id required')

    # try to convert to ObjectId
    try:
        oid = ObjectId(recipe_id)
    except Exception:
        # use as string id
        oid = recipe_id

    doc = recipes_coll.find_one({'_id': oid}) if isinstance(oid, ObjectId) else recipes_coll.find_one({'_id': recipe_id})
    if not doc:
        raise HTTPException(status_code=404, detail='Recipe not found in MongoDB')

    # Build text and create embedding
    if sentence_model is None:
        raise HTTPException(status_code=500, detail='Sentence model not loaded')

    text = build_text_for_embedding(doc)
    embedding = sentence_model.encode([text])[0].astype(np.float32)

    new_row = {
        'question': text,
        'answer': (doc.get('instructions') or doc.get('steps') or doc.get('content') or '')[:2000],
        'category': doc.get('category', 'recipes'),
        'embedding': embedding.tolist(),
        'meta': {'recipe_id': str(doc.get('_id')), 'title': doc.get('title'), 'source': 'recipes'},
        'source_type': 'recipes'
    }

    # Append to recipes_parquet
    try:
        if os.path.exists(recipes_parquet):
            df_existing = pd.read_parquet(recipes_parquet)
            df_new = pd.concat([df_existing, pd.DataFrame([new_row])], ignore_index=True)
        else:
            df_new = pd.DataFrame([new_row])
        df_new.to_parquet(recipes_parquet, index=False)
    except Exception as e:
        logger.error(f'Failed to append recipe parquet: {e}')
        raise HTTPException(status_code=500, detail='Failed to save recipe embedding')

    # Update in-memory df
    global df
    try:
        if df is None or df.empty:
            df = pd.DataFrame([new_row])
        else:
            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    except Exception as e:
        logger.warning(f'Failed to update in-memory df: {e}')

    return {'ok': True, 'recipe_id': str(doc.get('_id'))}


app = FastAPI(
    title="Cookify RAG Chatbot API",
    description="API cho chatbot t∆∞ v·∫•n n·∫•u ƒÉn s·ª≠ d·ª•ng RAG v·ªõi SentenceTransformers",
    version="2.0.0"
)

# C·∫•u h√¨nh CORS cho React frontend
allowed = os.getenv('ALLOWED_ORIGINS', 'http://localhost:3000').split(',')
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Register admin router
app.include_router(admin_router)

# Load d·ªØ li·ªáu khi kh·ªüi ƒë·ªông
load_data()

class Question(BaseModel):
    question: str

class ChatResponse(BaseModel):
    llm_answers: str
    suggestions: Optional[List[str]] = []
    source: str = "rag"
    score: Optional[float] = None
    similar_questions: Optional[List[dict]] = []

def search_similar_embeddings(query_embedding: np.ndarray, df: pd.DataFrame, top_k: int = 5, threshold: float = 0.3) -> pd.DataFrame:
    """T√¨m ki·∫øm c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng s·ª≠ d·ª•ng cosine similarity"""
    if df.empty:
        return pd.DataFrame()
    
    try:
        query_vector = np.array(query_embedding, dtype=np.float32).reshape(1, -1)
        embedding_matrix = np.array(df['embedding'].tolist(), dtype=np.float32)
        
        similarities = cosine_similarity(query_vector, embedding_matrix)[0]
        
        # G√°n similarity v√†o DataFrame
        df_with_similarity = df.copy()
        df_with_similarity['similarity'] = similarities
        
        # L·ªçc theo ng∆∞·ª°ng v√† s·∫Øp x·∫øp
        result = (
            df_with_similarity[df_with_similarity['similarity'] >= threshold]
            .sort_values(by='similarity', ascending=False)
            .head(top_k)
        )
        
        return result[['question', 'answer', 'category', 'similarity']]
    
    except Exception as e:
        logger.error(f"L·ªói trong search_similar_embeddings: {e}")
        return pd.DataFrame()

@app.post("/ask", response_model=ChatResponse)
async def receive_question(data: Question):
    """API endpoint ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi t·ª´ chatbot"""
    try:
        question = data.question.strip()
        
        if not question:
            raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
        
        logger.info(f"Nh·∫≠n c√¢u h·ªèi: {question}")
        
        # Ki·ªÉm tra model v√† d·ªØ li·ªáu
        if sentence_model is None or df.empty:
            return ChatResponse(
                llm_answers="Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng th·ª≠ l·∫°i sau! üòÖ",
                source="error",
                suggestions=["Th·ª≠ l·∫°i", "H·ªèi c√¢u kh√°c"]
            )
        
        # T·∫°o embedding cho c√¢u h·ªèi
        question_embedding = sentence_model.encode([question])[0]
        
        # T√¨m ki·∫øm c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng
        retrieval_docs = search_similar_embeddings(
            query_embedding=question_embedding, 
            df=df, 
            top_k=5, 
            threshold=0.3
        )
        
        # T·∫°o context t·ª´ c√°c c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng
        if not retrieval_docs.empty:
            document = "\n\n".join(
                f"C√¢u h·ªèi: {row['question']}\nTr·∫£ l·ªùi: {row['answer']}\nDanh m·ª•c: {row['category']}"
                for _, row in retrieval_docs.iterrows()
            )
            
            # T·∫°o suggestions t·ª´ c√°c c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng
            suggestions = [
                row['question'][:50] + "..." if len(row['question']) > 50 else row['question']
                for _, row in retrieval_docs.head(3).iterrows()
            ]
            
            similar_questions = [
                {
                    "question": row['question'],
                    "answer": row['answer'][:100] + "..." if len(row['answer']) > 100 else row['answer'],
                    "similarity": float(row['similarity']),
                    "category": row['category']
                }
                for _, row in retrieval_docs.head(3).iterrows()
            ]
            
            max_similarity = float(retrieval_docs['similarity'].max())
            
        else:
            document = "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü d·ªØ li·ªáu."
            suggestions = ["M√≥n nhanh 30 ph√∫t", "M√≥n cho gia ƒë√¨nh", "M√≥n Vi·ªát truy·ªÅn th·ªëng"]
            similar_questions = []
            max_similarity = 0.0
        
        # T·∫°o prompt cho Gemini
        prompt = f"""
B·∫°n l√† Chef AI Assistant - m·ªôt tr·ª£ l√Ω ·∫£o chuy√™n v·ªÅ n·∫•u ƒÉn v√† ·∫©m th·ª±c. 
H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch th√¢n thi·ªán, h·ªØu √≠ch v√† ch√≠nh x√°c.

N·∫øu c√≥ th√¥ng tin t·ª´ c∆° s·ªü d·ªØ li·ªáu, h√£y s·ª≠ d·ª•ng v√† tham kh·∫£o. 
N·∫øu kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ, h√£y ƒë∆∞a ra l·ªùi khuy√™n chung v·ªÅ n·∫•u ƒÉn d·ª±a tr√™n ki·∫øn th·ª©c c·ªßa b·∫°n.
Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán.

C√¢u h·ªèi: {question}

Th√¥ng tin tham kh·∫£o:
{document}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu v√† h·ªØu √≠ch.
"""
        
        # G·ªçi Gemini API
        try:
            response = gemini_model.generate_content(prompt)
            answer = response.text
            source = "rag" if not retrieval_docs.empty else "general"
            
        except Exception as gemini_error:
            logger.error(f"L·ªói Gemini API: {gemini_error}")
            # Fallback response
            if not retrieval_docs.empty:
                answer = f"D·ª±a tr√™n th√¥ng tin t√¥i c√≥:\n\n{retrieval_docs.iloc[0]['answer']}"
                source = "fallback"
            else:
                answer = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau! üòÖ"
                source = "error"
        
        logger.info(f"Tr·∫£ l·ªùi th√†nh c√¥ng v·ªõi similarity: {max_similarity:.3f}")
        
        return ChatResponse(
            llm_answers=answer,
            suggestions=suggestions,
            source=source,
            score=max_similarity,
            similar_questions=similar_questions
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"L·ªói kh√¥ng mong mu·ªën: {e}")
        raise HTTPException(
            status_code=500, 
            detail="ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i!"
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "model_loaded": sentence_model is not None,
        "data_loaded": not df.empty if df is not None else False,
        "total_questions": len(df) if df is not None and not df.empty else 0
    }

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Cookify RAG Chatbot API",
        "version": "2.0.0",
        "endpoints": {
            "/ask": "POST - G·ª≠i c√¢u h·ªèi",
            "/health": "GET - Ki·ªÉm tra tr·∫°ng th√°i",
            "/docs": "GET - API documentation"
        }
    }